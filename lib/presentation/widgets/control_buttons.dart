import 'package:flutter/material.dart';
import 'package:flutter_bloc/flutter_bloc.dart';

import '../bloc/speech_recognition/speech_recognition_bloc.dart';
import '../bloc/verse_tracking/verse_tracking_bloc.dart';

class ControlButtons extends StatelessWidget {
  const ControlButtons({super.key});

  @override
  Widget build(BuildContext context) {
    return BlocBuilder<SpeechRecognitionBloc, SpeechRecognitionState>(
      builder: (context, speechState) {
        return BlocBuilder<VerseTrackingBloc, VerseTrackingState>(
          builder: (context, verseState) {
            final bool isConnected = speechState is SpeechRecognitionConnected ||
                                   speechState is SpeechRecognitionListening ||
                                   speechState is SpeechRecognitionStopped;
            
            final bool isListening = speechState is SpeechRecognitionListening;
            
            final bool canStart = isConnected && !isListening && 
                                 verseState is VerseTrackingLoaded && 
                                 !verseState.isCompleted;
            
            return Column(
              children: [
                // Main control buttons
                Row(
                  mainAxisAlignment: MainAxisAlignment.spaceEvenly,
                  children: [
                    // Reset button
                    _buildControlButton(
                      onPressed: verseState is VerseTrackingLoaded
                          ? () {
                              // Stop listening first if active
                              if (isListening) {
                                context.read<SpeechRecognitionBloc>().add(StopListening());
                              }
                              // Reset verse progress
                              context.read<VerseTrackingBloc>().add(ResetProgress());
                            }
                          : null,
                      icon: Icons.refresh,
                      label: 'Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ†',
                      backgroundColor: Colors.orange,
                      foregroundColor: Colors.white,
                    ),
                    
                    // Main recording button
                    _buildMainButton(
                      context: context,
                      isListening: isListening,
                      canStart: canStart,
                      speechState: speechState,
                    ),
                    
                    // Connection button
                    _buildControlButton(
                      onPressed: () {
                        if (isConnected) {
                          context.read<SpeechRecognitionBloc>().add(DisconnectFromSTT());
                        } else {
                          context.read<SpeechRecognitionBloc>().add(ConnectToSTT());
                        }
                      },
                      icon: isConnected ? Icons.wifi_off : Icons.wifi,
                      label: isConnected ? 'Ù‚Ø·Ø¹ Ø§Ù„Ø§ØªØµØ§Ù„' : 'Ø§ØªØµØ§Ù„',
                      backgroundColor: isConnected ? Colors.red.shade600 : Colors.blue,
                      foregroundColor: Colors.white,
                    ),
                  ],
                ),
                
                // Status text
                const SizedBox(height: 12),
                Container(
                  padding: const EdgeInsets.symmetric(
                    horizontal: 16,
                    vertical: 8,
                  ),
                  decoration: BoxDecoration(
                    color: Colors.grey.shade100,
                    borderRadius: BorderRadius.circular(20),
                  ),
                  child: Text(
                    _getStatusMessage(speechState, verseState),
                    style: TextStyle(
                      fontSize: 12,
                      color: Colors.grey.shade700,
                      fontWeight: FontWeight.w500,
                    ),
                    textAlign: TextAlign.center,
                  ),
                ),
              ],
            );
          },
        );
      },
    );
  }

  Widget _buildMainButton({
    required BuildContext context,
    required bool isListening,
    required bool canStart,
    required SpeechRecognitionState speechState,
  }) {
    return GestureDetector(
      onTap: canStart || isListening
          ? () {
              if (isListening) {
                context.read<SpeechRecognitionBloc>().add(StopListening());
              } else {
                context.read<SpeechRecognitionBloc>().add(StartListening());
              }
            }
          : null,
      child: AnimatedContainer(
        duration: const Duration(milliseconds: 300),
        width: 80,
        height: 80,
        decoration: BoxDecoration(
          color: _getMainButtonColor(isListening, canStart),
          shape: BoxShape.circle,
          boxShadow: [
            BoxShadow(
              color: _getMainButtonColor(isListening, canStart).withOpacity(0.3),
              spreadRadius: isListening ? 6 : 2,
              blurRadius: isListening ? 12 : 6,
              offset: const Offset(0, 2),
            ),
          ],
        ),
        child: Icon(
          isListening ? Icons.stop : Icons.mic,
          color: Colors.white,
          size: 36,
        ),
      ),
    );
  }

  Widget _buildControlButton({
    required VoidCallback? onPressed,
    required IconData icon,
    required String label,
    required Color backgroundColor,
    required Color foregroundColor,
  }) {
    return Column(
      mainAxisSize: MainAxisSize.min,
      children: [
        ElevatedButton(
          onPressed: onPressed,
          style: ElevatedButton.styleFrom(
            backgroundColor: backgroundColor,
            foregroundColor: foregroundColor,
            shape: const CircleBorder(),
            padding: const EdgeInsets.all(16),
            elevation: onPressed != null ? 3 : 1,
          ),
          child: Icon(icon, size: 24),
        ),
        const SizedBox(height: 6),
        Text(
          label,
          style: TextStyle(
            fontSize: 12,
            fontWeight: FontWeight.w500,
            color: onPressed != null ? Colors.black87 : Colors.grey,
          ),
        ),
      ],
    );
  }

  Color _getMainButtonColor(bool isListening, bool canStart) {
    if (isListening) {
      return Colors.red;
    } else if (canStart) {
      return Colors.green;
    } else {
      return Colors.grey;
    }
  }

  String _getStatusMessage(
    SpeechRecognitionState speechState,
    VerseTrackingState verseState,
  ) {
    if (verseState is VerseTrackingLoaded && verseState.isCompleted) {
      return 'ğŸ‰ Ù…Ø¨Ø±ÙˆÙƒ! Ù„Ù‚Ø¯ Ø£ÙƒÙ…Ù„Øª Ø³ÙˆØ±Ø© Ø§Ù„ÙØ§ØªØ­Ø©';
    }
    
    if (speechState is SpeechRecognitionListening) {
      return 'Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹... ØªØ­Ø¯Ø« Ø§Ù„Ø¢Ù† Ù„ØªÙ„Ø§ÙˆØ© Ø§Ù„Ø¢ÙŠØ©';
    } else if (speechState is SpeechRecognitionConnecting) {
      return 'Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø®Ø§Ø¯Ù… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØª...';
    } else if (speechState is SpeechRecognitionDisconnected || 
               speechState is SpeechRecognitionError) {
      return 'ØºÙŠØ± Ù…ØªØµÙ„ - Ø§Ø¶ØºØ· "Ø§ØªØµØ§Ù„" Ù„Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰';
    } else if (speechState is SpeechRecognitionConnected) {
      if (verseState is VerseTrackingLoaded) {
        return 'Ø§Ø¶ØºØ· Ø¹Ù„Ù‰ Ø²Ø± Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ† Ù„Ø¨Ø¯Ø¡ ØªÙ„Ø§ÙˆØ© Ø§Ù„Ø¢ÙŠØ© ${verseState.currentVerseIndex + 1}';
      }
      return 'Ø¬Ø§Ù‡Ø² Ù„Ù„Ø¨Ø¯Ø¡';
    } else if (speechState is SpeechRecognitionStopped) {
      return 'ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªØ³Ø¬ÙŠÙ„ - ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø¨Ø¯Ø¡ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰';
    }
    
    return 'ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø§ØªØµØ§Ù„ ÙˆØ­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰';
  }
}